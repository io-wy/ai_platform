# QA System LLM Configuration
# ============================
# 用于知识问答系统的 LLM 配置

# LLM Provider: openai, azure_openai, vllm, ollama, anthropic, custom
LLM_PROVIDER=openai

# Model name - QA 推荐使用更精确的模型
LLM_MODEL=gpt-4o-mini

# API Configuration
LLM_API_KEY=your_api_key_here
LLM_API_BASE=https://api.openai.com/v1

# Generation Parameters - QA 需要较低温度保证准确性
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=2000
LLM_TOP_P=1.0

# Request Settings
LLM_TIMEOUT=60.0
LLM_MAX_RETRIES=3
