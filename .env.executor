# Task Agent - Executor LLM Configuration
# ========================================
# 用于任务执行的 LLM 配置

# LLM Provider: openai, azure_openai, vllm, ollama, anthropic, custom
LLM_PROVIDER=openai

# Model name - 执行任务可以使用较快的模型
LLM_MODEL=gpt-4o-mini

# API Configuration
LLM_API_KEY=your_api_key_here
LLM_API_BASE=https://api.openai.com/v1

# Generation Parameters - 执行需要较低温度保证准确性
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=2000
LLM_TOP_P=1.0

# Request Settings
LLM_TIMEOUT=60.0
LLM_MAX_RETRIES=3
